{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "![ML_overview](ML_overview.png \"ML_overview\")\n",
    "\n",
    "\n",
    "### [Definition @wikipedia](https://en.wikipedia.org/wiki/Machine_learning)\n",
    "\n",
    ">\"Machine learning is a scientific discipline that is concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data, such as from sensor data or databases.\"\n",
    "\n",
    "### Learning\n",
    "\n",
    "- [**Definition** @wikipedia](https://en.wikipedia.org/wiki/Machine_learning)\n",
    "\n",
    "    Learning is the act of acquiring new, or modifying and reinforcing, existing knowledge, behaviors, skills, values, or preferences and may involve synthesizing different types of information.\n",
    "    \n",
    "    \n",
    "- The **author's** opinion:\n",
    "\n",
    "    In simple terms, historical data or observations are used to predict or derive actionable tasks.\n",
    "    \n",
    "    \n",
    "- **Data**:\n",
    "\n",
    "\n",
    "    Unlabeled Data: ordinary the raw forms of the data\n",
    "    \n",
    "    Labeled Data: when a meaning is attached to the data\n",
    "    \n",
    "- **Tasks**:\n",
    "\n",
    "\n",
    "    A task is a problem that a machine learning algorithm to solve\n",
    "    \n",
    "    \n",
    "- **Algorithms** (***By subfields***):\n",
    "        \n",
    "    ***supervised***: inferring a function from labeled training data (wikipedia)\n",
    "\n",
    "    ***unsupervised***: inferring a function to describe hidden structure from unlabeled data (wikipedia)\n",
    "\n",
    "    ***semi-supervised***: learning using both labeled and unlabeled data to infer models better\n",
    "\n",
    "    ***reinforcement***: (this book)\n",
    "\n",
    "        learning that focuses on maximizing the rewards from the result, \n",
    "        also called credit assessment learning \n",
    "        1. Rewards will be issued for decisions made\n",
    "        2. Results are not be seen immediately, rather a sequence of steps maybe required to be executed.\n",
    "        3. The goal of the learning algorithm is to maximize the cumulative rewards\n",
    "\n",
    "    ***deep learning***: (wikipedia) (I think the wikipedia definition is better)\n",
    "\n",
    "        1. Deep learning has been characterized as a buzzword, or a rebranding of neural networks\n",
    "        2. Deep learning (deep structured learning, hierarchical learning or deep machine learning) \n",
    "           is a branch of machine learning based on a set of algorithms that attempt to model high-level \n",
    "           abstractions in data by using multiple processing layers, with complex structures or otherwise, \n",
    "           composed of multiple non-linear transformations\n",
    "        3. Various deep learning architectures such as deep neural networks, convolutional deep neural networks, \n",
    "           deep belief networks and recurrent neural networks have been applied to fields like computer vision, \n",
    "           automatic speech recognition, natural language processing, audio recognition and bioinformatic\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Algorithms** ( ***By problem categories***):\n",
    "        \n",
    "    ***Classification***: ( <a href=https://en.wikipedia.org/wiki/Statistical_classification> Def at wikipedia </a> )\n",
    "\n",
    "        1. classification is the problem of identifying to which of a set of categories (sub-populations) \n",
    "           a new observation belongs, on the basis of a training set of data containing observations \n",
    "           (or instances) whose category membership is known\n",
    "        \n",
    "        2. outputs are discrete\n",
    "        \n",
    "        3. supervised learning approach\n",
    "\n",
    "    ***Regression***: \n",
    "    \n",
    "        1. outputs are continuos\n",
    "        \n",
    "        2. supervised learning approach\n",
    "    \n",
    "    ***Clustering***: (the author)\n",
    "    \n",
    "        1. In short, clustering is a classification analysis that does not start with a specific target in mind \n",
    "           (e.g. good/bad, will buy/will not buy) \n",
    "        \n",
    "        2.  unsupervised learning approach.\n",
    "        \n",
    "    ***Optimization***:\n",
    "    \n",
    "        I think it is NOT appropriate to place this concept here. \n",
    "        It is a match concept rather than a machine learning one.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Models**\n",
    "\n",
    "    A model describes data observed in a system. E.g.\n",
    "    \n",
    "    - ***Logical models***\n",
    "\n",
    "    - ***Geometric models***\n",
    "\n",
    "    - ***Probabilistic models***\n",
    "    \n",
    "\n",
    "- **Data inconsistencies** in Machine learning\n",
    "\n",
    "\n",
    "    Under-fitting\n",
    "    \n",
    "    Over-fitting\n",
    "    \n",
    "    Data instability\n",
    "    \n",
    "    Unpredictable future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measures\n",
    "\n",
    "#### 1. Discrete Outputs: Accuracy, Recall, Precision\n",
    "\n",
    "- Assume total observations is 10,000\n",
    "\n",
    "\n",
    "- Actual and predicted:\n",
    "\n",
    "<table>\n",
    "<tr><td>_</td><td>Predicted Positive</td><td>Predicted Negtive</td></tr>\n",
    "<tr><td>Actual Positive</td><td><b>TP</b> (True Positive): 500</td><td><b>FN</b> (False Negtive): 400</td></tr>\n",
    "<tr><td>Actual Negtive</td><td><b>FP</b> (False Positive): 100</td><td><b>TN</b> (True Negtive): 9000</td></tr>\n",
    "</table>\n",
    "\n",
    "- **Accuracy**:\n",
    "\n",
    "    is the percentage of predictions that were correct\n",
    "    \n",
    "    = (TP+TN) / Total = (500+9000) / 10000 = 95%\n",
    "    \n",
    "\n",
    "- **Recall**:\n",
    "\n",
    "    is the percentage of predictions that were correct among the total cases that were predicted positive\n",
    "    \n",
    "    = TP / (TP + FP) = 500 / (500 + 100) = 83.3%\n",
    "    \n",
    "    \n",
    "- **Precision**:\n",
    "\n",
    "    is the percentage of predictions that were correct among the total cases that were actual positive\n",
    "    \n",
    "    = TP / (TP + FN) = 500 / (500 + 400) = 55.5%\n",
    "\n",
    "\n",
    "#### 2. Continuous Outputs: \n",
    "\n",
    "- **MSE** (mean square error) or **MSD** (mean-square deviation)\n",
    "    ![MEAN SQUARED ERROR](mse.jpg 'MSE')\n",
    "        where:\n",
    "\n",
    "            Pi: predicted value\n",
    "            Ai: actual value\n",
    "        \n",
    "    **RMSE** (root-mean-square error) or **RMSD** (root-mean-square deviation): the square root of this quantity.\n",
    "    \n",
    "\n",
    "- **MAE** (mean absolute error) or **MAD** (mean absolute deviation)\n",
    "    ![MEAN ABSOLUTE ERROR](mae.jpg 'MAE')\n",
    "\n",
    "\n",
    "- **NMSE** (normalized mean square error)\n",
    "    \n",
    "    Comparing with a benchmarking index.\n",
    "    \n",
    "    ![NORMALIZED MEAN SQUARED ERROR](nmse.jpg 'NMSE')\n",
    "\n",
    "- **NMAE** (normalized mean absolute error)\n",
    "    \n",
    "    Similiar to NMSE\n",
    "\n",
    "\n",
    "#### 3. Bias–Variance Tradeoff \n",
    "\n",
    "- [Definition at wikipedia](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)\n",
    "    \n",
    "    In statistics and machine learning, the bias–variance tradeoff (or dilemma) is the problem of simultaneously minimizing **two sources of error** that prevent supervised learning algorithms from generalizing beyond their training set:\n",
    "    ![Bias Variance Tradeoff](bias_variance_tradeoff.jpg 'bias_variance_tradeoff') \n",
    "    \n",
    "    - **TotalErr(x) = Bias^2 + Variance + Irreducible Error**\n",
    "    \n",
    "    - The **bias** is error from erroneous assumptions in the learning algorithm. \n",
    "        - High bias can cause an algorithm to miss the relevant relations between features and target outputs (**underfitting**).\n",
    "        - Normally for less complex models, the bias is high\n",
    "    \n",
    "    - The **variance** is error from sensitivity to small fluctuations in the training set. \n",
    "        - High variance can cause **overfitting**: modeling the random noise in the training data, rather than the intended outputs.\n",
    "        - Normally for higher complex models, the variance is high\n",
    "\n",
    "\n",
    "- If a model has a high bias, how does its error vary as a function of the amount of data?\n",
    "    ![Bias vs Data Size](bias_data_size.jpg 'bias_data_size') \n",
    "    - Training set error goes up as data size increases\n",
    "    - Testing set error goes down\n",
    "    - As the model gets more refined, these 2 kinds of errors tend to be the same (converge)\n",
    "\n",
    "\n",
    "- The remedy for high bias:\n",
    "        \n",
    "    - Maybe too few features selected ==> choose more features\n",
    "    - Increase the complexity of the model \n",
    "    - Increasing the data size will not be of much help\n",
    "    \n",
    "    \n",
    "- The remedy for high variance:\n",
    "    \n",
    "    Training set error and testing set error tend not to converge.\n",
    "    \n",
    "    ![Variance vs Data Size](variance_data_size.jpg 'variance_data_size') \n",
    "    \n",
    "    - Maybe too many features selected, reduce the features\n",
    "    - Decrease the complexity of the model\n",
    "    - Increasing the data size will be some help\n",
    "\n",
    "\n",
    "#### PAC \n",
    "\n",
    "I don't see the PAC concept introduced in thie section is much helpful.\n",
    "\n",
    "Two types of uncertainties per Probably Approximately Correct (**PAC**) theory:\n",
    "\n",
    "- Approximate: \n",
    "    This measures the extent to which an error is accepted for a hypothesis\n",
    "    \n",
    "- Probability: \n",
    "    This measure is the percentage certainty of the hypothesis being correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
